{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d77415b-86ed-4b14-8146-e73dec8e04c8",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5a92c-9bc7-4809-9130-88da543a6a4f",
   "metadata": {},
   "source": [
    "JAVA C AND C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9ffc99-e376-4190-9a9f-f8d248610383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to your code file:\n",
      " D:\\BHAVIKA\\sem_4\\toc\\ass\\test2.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "| Token Type        | Value              |\n",
      "+===================+====================+\n",
      "| Keyword           | public             |\n",
      "+-------------------+--------------------+\n",
      "| Keyword           | class              |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | Main               |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | {                  |\n",
      "+-------------------+--------------------+\n",
      "| Keyword           | public             |\n",
      "+-------------------+--------------------+\n",
      "| Keyword           | static             |\n",
      "+-------------------+--------------------+\n",
      "| Keyword           | void               |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | main               |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | (                  |\n",
      "+-------------------+--------------------+\n",
      "| Class Name        | String             |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | []args             |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | )                  |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | {                  |\n",
      "+-------------------+--------------------+\n",
      "| Keyword           | int                |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | x                  |\n",
      "+-------------------+--------------------+\n",
      "| Operator          | =                  |\n",
      "+-------------------+--------------------+\n",
      "| Number            | 5                  |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | ;                  |\n",
      "+-------------------+--------------------+\n",
      "| Keyword           | int                |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | y                  |\n",
      "+-------------------+--------------------+\n",
      "| Operator          | =                  |\n",
      "+-------------------+--------------------+\n",
      "| Number            | 10                 |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | ;                  |\n",
      "+-------------------+--------------------+\n",
      "| Keyword           | int                |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | result             |\n",
      "+-------------------+--------------------+\n",
      "| Operator          | =                  |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | x                  |\n",
      "+-------------------+--------------------+\n",
      "| Operator          | +                  |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | y                  |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | ;                  |\n",
      "+-------------------+--------------------+\n",
      "| Standard Function | System.out.println |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | (                  |\n",
      "+-------------------+--------------------+\n",
      "| String            | \"The result is: \"  |\n",
      "+-------------------+--------------------+\n",
      "| Operator          | +                  |\n",
      "+-------------------+--------------------+\n",
      "| Identifier        | result             |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | )                  |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | ;                  |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | }                  |\n",
      "+-------------------+--------------------+\n",
      "| Symbol            | }                  |\n",
      "+-------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Token class for C, Java, and C++\n",
    "class Token:\n",
    "    def __init__(self, token_type, value):\n",
    "        self.token_type = token_type\n",
    "        self.value = value\n",
    "\n",
    "# C Lexer\n",
    "class CLexer:\n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        self.tokens = []\n",
    "        self.keywords = self.get_keywords()  # C keywords\n",
    "        self.operators = self.get_operators()  # C operators\n",
    "        self.standard_functions = self.get_standard_functions()  # C Standard Functions\n",
    "        self.current_state = 'start'  # Initial state\n",
    "        self.current_token = ''  # Current token being constructed\n",
    "\n",
    "    def get_keywords(self):\n",
    "        return set([\n",
    "            'auto', 'break', 'case', 'char', 'const', 'continue', 'default',\n",
    "            'do', 'double', 'else', 'enum', 'extern', 'float', 'for', 'goto',\n",
    "            'if', 'inline', 'int', 'long', 'register', 'restrict', 'return',\n",
    "            'short', 'signed', 'sizeof', 'static', 'struct', 'switch',\n",
    "            'typedef', 'union', 'unsigned', 'void', 'volatile', 'while'\n",
    "        ])\n",
    "\n",
    "    def get_operators(self):\n",
    "        return set([\n",
    "            '==', '!=', '>=', '<=', '++', '--', '+=', '-=', '*=', '/=', '%=',\n",
    "            '&&', '||', '>', '<', '+', '-', '*', '/', '%', '=', '!', '&',\n",
    "            '|', '^', '<<', '>>', '~'\n",
    "        ])\n",
    "\n",
    "    def get_standard_functions(self):\n",
    "        return set([\n",
    "            'printf', 'scanf', 'malloc', 'free', 'exit', 'fopen', 'fclose',\n",
    "            'fgets', 'fputs', 'fprintf', 'fscanf', 'strcpy', 'strcat',\n",
    "            'strlen', 'strcmp', 'atoi', 'atof', 'abs', 'pow', 'sqrt'\n",
    "        ])\n",
    "\n",
    "    def add_token(self, token_type):\n",
    "        if self.current_token:  # Only add if there's a current token\n",
    "            # Check if the token is a standard function\n",
    "            if token_type == 'Identifier' and self.current_token in self.standard_functions:\n",
    "                self.tokens.append(Token('Standard Function', self.current_token))\n",
    "            else:\n",
    "                self.tokens.append(Token(token_type, self.current_token))\n",
    "        self.current_token = ''  # Reset current token\n",
    "\n",
    "    def transition(self, char):\n",
    "        if self.current_state == 'start':\n",
    "            if char == '#':\n",
    "                self.current_state = 'preprocessor'\n",
    "                self.current_token = char\n",
    "            elif char.isalpha() or char == '_':\n",
    "                self.current_state = 'identifier'\n",
    "                self.current_token += char\n",
    "            elif char.isdigit():\n",
    "                self.current_state = 'number'\n",
    "                self.current_token += char\n",
    "            elif char in ('\"', \"'\"):\n",
    "                self.current_state = 'string'\n",
    "                self.current_token += char\n",
    "            elif char in '(){};,.':\n",
    "                self.tokens.append(Token('Symbol', char))  # Add single character symbols\n",
    "            elif char in self.operators:\n",
    "                self.current_token = char  # Start building an operator\n",
    "                self.current_state = 'operator'\n",
    "            elif char.isspace():\n",
    "                pass  # Ignore whitespace\n",
    "            else:\n",
    "                self.current_token += char  # Any other character\n",
    "\n",
    "        elif self.current_state == 'preprocessor':\n",
    "            if char.isspace():\n",
    "                if self.current_token == '#include':\n",
    "                    self.add_token('Preprocessor')\n",
    "                    self.current_state = 'header'\n",
    "            else:\n",
    "                self.current_token += char  # Continue collecting the preprocessor keyword\n",
    "\n",
    "        elif self.current_state == 'header':\n",
    "            if char == '<':\n",
    "                self.current_token = char  # Start of a system header\n",
    "            elif char == '>':\n",
    "                self.current_token += char  # End of the header\n",
    "                self.add_token('Header')  # Add token as Header\n",
    "                self.current_state = 'start'\n",
    "            else:\n",
    "                self.current_token += char  # Collecting header name\n",
    "\n",
    "        elif self.current_state == 'identifier':\n",
    "            if char.isalnum() or char == '_':\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                if self.current_token in self.keywords:\n",
    "                    self.add_token('Keyword')\n",
    "                else:\n",
    "                    self.add_token('Identifier')\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "\n",
    "        elif self.current_state == 'number':\n",
    "            if char.isdigit() or char == '.':\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                self.add_token('Number')\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "\n",
    "        elif self.current_state == 'string':\n",
    "            self.current_token += char\n",
    "            if char == self.current_token[0]:  # End of string\n",
    "                self.add_token('String')\n",
    "                self.current_state = 'start'\n",
    "\n",
    "        elif self.current_state == 'operator':\n",
    "            # Check if the operator can continue (like `==` or `+=`)\n",
    "            if self.current_token + char in self.operators:\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                self.add_token('Operator')  # Finalize the operator\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "\n",
    "    def tokenize(self):\n",
    "        for char in self.code:\n",
    "            self.transition(char)\n",
    "        # Add any remaining token after the loop\n",
    "        if self.current_token:\n",
    "            if self.current_state == 'identifier':\n",
    "                if self.current_token in self.keywords:\n",
    "                    self.add_token('Keyword')\n",
    "                else:\n",
    "                    self.add_token('Identifier')\n",
    "            elif self.current_state == 'number':\n",
    "                self.add_token('Number')\n",
    "            elif self.current_state == 'string':\n",
    "                self.add_token('String')\n",
    "            elif self.current_state == 'operator':\n",
    "                self.add_token('Operator')\n",
    "\n",
    "        return self.tokens\n",
    "\n",
    "# Java Lexer\n",
    "class JavaLexer:\n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        self.tokens = []\n",
    "        self.keywords = self.get_keywords()  # Java keywords\n",
    "        self.operators = self.get_operators()  # Java operators\n",
    "        self.standard_functions = self.get_standard_functions()  # Java Standard Functions\n",
    "        self.class_names = self.get_class_names()  # Java Class Names\n",
    "        self.current_state = 'start'  # Initial state\n",
    "        self.current_token = ''  # Current token being constructed\n",
    "\n",
    "    def get_keywords(self):\n",
    "        return set([\n",
    "            'abstract', 'assert', 'boolean', 'break', 'byte', 'case', 'catch',\n",
    "            'char', 'class', 'const', 'continue', 'default', 'do', 'double',\n",
    "            'else', 'enum', 'extends', 'final', 'finally', 'float', 'for',\n",
    "            'if', 'implements', 'import', 'instanceof', 'int', 'interface',\n",
    "            'long', 'native', 'new', 'package', 'private', 'protected',\n",
    "            'public', 'return', 'short', 'static', 'strictfp', 'super',\n",
    "            'switch', 'synchronized', 'this', 'throw', 'throws', 'transient',\n",
    "            'try', 'void', 'volatile', 'while'\n",
    "        ])\n",
    "\n",
    "    def get_operators(self):\n",
    "        return set([\n",
    "            '==', '!=', '>=', '<=', '++', '--', '+=', '-=', '*=', '/=', '%=',\n",
    "            '&&', '||', '>', '<', '+', '-', '*', '/', '%', '=', '!', '&',\n",
    "            '|', '^', '<<', '>>', '~'\n",
    "        ])\n",
    "\n",
    "    def get_standard_functions(self):\n",
    "        return set([\n",
    "            'System.out.println', 'System.out.print', 'Math.abs', 'Math.max', \n",
    "            'Math.min', 'Math.sqrt', 'Integer.parseInt', 'Double.parseDouble'\n",
    "        ])\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return set(['String', 'Integer', 'Double', 'Math'])\n",
    "\n",
    "    def add_token(self, token_type):\n",
    "        if self.current_token:  # Only add if there's a current token\n",
    "            # Check if the token is a class name\n",
    "            if self.current_token in self.class_names:\n",
    "                self.tokens.append(Token('Class Name', self.current_token))\n",
    "            # Check if the token is a standard function\n",
    "            elif token_type == 'Identifier' and self.current_token in self.standard_functions:\n",
    "                self.tokens.append(Token('Standard Function', self.current_token))\n",
    "            else:\n",
    "                self.tokens.append(Token(token_type, self.current_token))\n",
    "        self.current_token = ''  # Reset current token\n",
    "\n",
    "    def transition(self, char):\n",
    "        if self.current_state == 'start':\n",
    "            if char.isalpha() or char == '_':\n",
    "                self.current_state = 'identifier'\n",
    "                self.current_token += char\n",
    "            elif char.isdigit():\n",
    "                self.current_state = 'number'\n",
    "                self.current_token += char\n",
    "            elif char in ('\"', \"'\"):\n",
    "                self.current_state = 'string'\n",
    "                self.current_token += char\n",
    "            elif char in '(){};,.':\n",
    "                self.tokens.append(Token('Symbol', char))  # Add single character symbols\n",
    "            elif char in self.operators:\n",
    "                self.current_token += char  # Start building an operator\n",
    "                self.current_state = 'operator'\n",
    "            elif char.isspace():\n",
    "                pass  # Ignore whitespace\n",
    "            else:\n",
    "                self.current_token += char  # Any other character\n",
    "\n",
    "        elif self.current_state == 'identifier':\n",
    "            if char == '.':\n",
    "                self.current_token += char\n",
    "            elif char.isalnum() or char == '_':\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                if self.current_token in self.keywords:\n",
    "                    self.add_token('Keyword')\n",
    "                elif 'System.out' in self.current_token:  # Check for System.out calls\n",
    "                    self.add_token('Standard Function')  # Handle System.out specifically\n",
    "                else:\n",
    "                    self.add_token('Identifier')\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "\n",
    "        elif self.current_state == 'number':\n",
    "            if char.isdigit() or char == '.':\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                self.add_token('Number')\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "\n",
    "        elif self.current_state == 'string':\n",
    "            self.current_token += char\n",
    "            if char == self.current_token[0]:  # End of string\n",
    "                self.add_token('String')\n",
    "                self.current_state = 'start'\n",
    "\n",
    "        elif self.current_state == 'operator':\n",
    "            # Check if the operator can continue (like `==` or `+=`)\n",
    "            if self.current_token + char in self.operators:\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                self.add_token('Operator')  # Finalize the operator\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "\n",
    "    def tokenize(self):\n",
    "        for char in self.code:\n",
    "            self.transition(char)\n",
    "        # Add any remaining token after the loop\n",
    "        if self.current_token:\n",
    "            if self.current_state == 'identifier':\n",
    "                if self.current_token in self.keywords:\n",
    "                    self.add_token('Keyword')\n",
    "                else:\n",
    "                    self.add_token('Identifier')\n",
    "            elif self.current_state == 'number':\n",
    "                self.add_token('Number')\n",
    "            elif self.current_state == 'string':\n",
    "                self.add_token('String')\n",
    "            elif self.current_state == 'operator':\n",
    "                self.add_token('Operator')\n",
    "\n",
    "        return self.tokens\n",
    "\n",
    "# C++ Lexer\n",
    "class CppLexer:\n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        self.tokens = []\n",
    "        self.keywords = self.get_keywords()  # C++ keywords\n",
    "        self.operators = self.get_operators()  # C++ operators\n",
    "        self.standard_functions = self.get_standard_functions()  # C++ Standard Functions\n",
    "        self.class_names = self.get_class_names()  # C++ Class Names\n",
    "        self.current_state = 'start'  # Initial state\n",
    "        self.current_token = ''  # Current token being constructed\n",
    "\n",
    "    def get_keywords(self):\n",
    "        return set([\n",
    "            'alignas', 'alignof', 'and', 'and_eq', 'asm', 'auto', 'bitand', \n",
    "            'bitor', 'bool', 'break', 'case', 'catch', 'char', 'char8_t', \n",
    "            'char16_t', 'char32_t', 'class', 'compl', 'concept', 'const', \n",
    "            'constexpr', 'const_cast', 'continue', 'co_await', 'co_return', \n",
    "            'decltype', 'default', 'delete', 'do', 'double', 'dynamic_cast', \n",
    "            'else', 'enum', 'explicit', 'export', 'extern', 'false', 'float', \n",
    "            'for', 'friend', 'goto', 'if', 'inline', 'int', 'long', 'mutable', \n",
    "            'namespace', 'new', 'noexcept', 'not', 'not_eq', 'nullptr', \n",
    "            'operator', 'or', 'or_eq', 'private', 'protected', 'public', \n",
    "            'reflexpr', 'register', 'reinterpret_cast', 'requires', 'return', \n",
    "            'short', 'signed', 'sizeof', 'static', 'static_assert', 'static_cast', \n",
    "            'struct', 'switch', 'template', 'this', 'thread_local', 'throw', \n",
    "            'true', 'try', 'typedef', 'typeid', 'typename', 'union', \n",
    "            'unsigned', 'using', 'virtual', 'void', 'volatile', 'wchar_t', \n",
    "            'while', 'xor', 'xor_eq'\n",
    "        ])\n",
    "\n",
    "    def get_operators(self):\n",
    "        return set([\n",
    "            '==', '!=', '>=', '<=', '++', '--', '+=', '-=', '*=', '/=', '%=',\n",
    "            '&&', '||', '>', '<', '+', '-', '*', '/', '%', '=', '!', '&',\n",
    "            '|', '^', '<<', '>>', '~', '->', '::'\n",
    "        ])\n",
    "\n",
    "    def get_standard_functions(self):\n",
    "        return set([\n",
    "            'std::cout', 'std::cin', 'std::endl', 'std::string', 'std::vector', \n",
    "            'std::map', 'std::set', 'std::abs', 'std::pow', 'std::sqrt'\n",
    "        ])\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return set(['std::string', 'std::vector', 'std::map', 'std::set'])\n",
    "\n",
    "    def add_token(self, token_type):\n",
    "        if self.current_token:  # Only add if there's a current token\n",
    "            # Check if the token is a class name\n",
    "            if self.current_token in self.class_names:\n",
    "                self.tokens.append(Token('Class Name', self.current_token))\n",
    "            # Check if the token is a standard function\n",
    "            elif token_type == 'Identifier' and self.current_token in self.standard_functions:\n",
    "                self.tokens.append(Token('Standard Function', self.current_token))\n",
    "            else:\n",
    "                self.tokens.append(Token(token_type, self.current_token))\n",
    "        self.current_token = ''  # Reset current token\n",
    "\n",
    "    def transition(self, char):\n",
    "        if self.current_state == 'start':\n",
    "            if char == '#':\n",
    "                self.current_state = 'preprocessor'\n",
    "                self.current_token += char\n",
    "            elif char.isalpha() or char == '_':\n",
    "                self.current_state = 'identifier'\n",
    "                self.current_token += char\n",
    "            elif char.isdigit():\n",
    "                self.current_state = 'number'\n",
    "                self.current_token += char\n",
    "            elif char in ('\"', \"'\"):\n",
    "                self.current_state = 'string'\n",
    "                self.current_token += char\n",
    "            elif char in '(){};,.':\n",
    "                self.tokens.append(Token('Symbol', char))  # Add single character symbols\n",
    "            elif char in self.operators:\n",
    "                self.current_token += char  # Start building an operator\n",
    "                self.current_state = 'operator'\n",
    "            elif char.isspace():\n",
    "                pass  # Ignore whitespace\n",
    "            else:\n",
    "                self.current_token += char  # Any other character\n",
    "    \n",
    "        elif self.current_state == 'preprocessor':\n",
    "            if char.isspace():\n",
    "                if self.current_token == '#include':\n",
    "                    self.add_token('Preprocessor')  # Add as Preprocessor\n",
    "                    self.current_state = 'header'\n",
    "            else:\n",
    "                self.current_token += char  # Continue collecting the preprocessor keyword\n",
    "    \n",
    "        elif self.current_state == 'header':\n",
    "            if char == '<':\n",
    "                self.current_token = char  # Start of a system header\n",
    "            elif char == '>':\n",
    "                self.current_token += char  # End of the header\n",
    "                self.add_token('Header')  # Add token as Header\n",
    "                self.current_state = 'start'\n",
    "            else:\n",
    "                self.current_token += char  # Collecting header name\n",
    "    \n",
    "        elif self.current_state == 'identifier':\n",
    "            if char.isalnum() or char == '_' or char == ':':  # Support '::' in identifiers\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                if self.current_token.startswith('std::'):  # Handle std:: namespace\n",
    "                    if self.current_token in self.standard_functions:\n",
    "                        self.add_token('Standard Function')\n",
    "                    else:\n",
    "                        self.add_token('Identifier')  # Fallback if not a standard function\n",
    "                elif self.current_token in self.class_names:\n",
    "                    self.add_token('Class Name')\n",
    "                elif self.current_token in self.keywords:\n",
    "                    self.add_token('Keyword')\n",
    "                else:\n",
    "                    self.add_token('Identifier')\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "    \n",
    "        elif self.current_state == 'number':\n",
    "            if char.isdigit() or char == '.':\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                self.add_token('Number')\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "    \n",
    "        elif self.current_state == 'string':\n",
    "            self.current_token += char\n",
    "            if char == self.current_token[0]:  # End of string\n",
    "                self.add_token('String')\n",
    "                self.current_state = 'start'\n",
    "    \n",
    "        elif self.current_state == 'operator':\n",
    "            # Check if the operator can continue (like `==` or `+=`)\n",
    "            if self.current_token + char in self.operators:\n",
    "                self.current_token += char\n",
    "            else:\n",
    "                self.add_token('Operator')  # Finalize the operator\n",
    "                self.current_state = 'start'\n",
    "                self.transition(char)  # Process the next character\n",
    "\n",
    "\n",
    "    def tokenize(self):\n",
    "        for char in self.code:\n",
    "            self.transition(char)\n",
    "        # Add any remaining token after the loop\n",
    "        if self.current_token:\n",
    "            if self.current_state == 'identifier':\n",
    "                if self.current_token in self.keywords:\n",
    "                    self.add_token('Keyword')\n",
    "                else:\n",
    "                    self.add_token('Identifier')\n",
    "            elif self.current_state == 'number':\n",
    "                self.add_token('Number')\n",
    "            elif self.current_state == 'string':\n",
    "                self.add_token('String')\n",
    "            elif self.current_state == 'operator':\n",
    "                self.add_token('Operator')\n",
    "\n",
    "        return self.tokens\n",
    "\n",
    "\n",
    "def generate_token_table(tokens):\n",
    "    table = []\n",
    "    for token in tokens:\n",
    "        table.append([token.token_type, token.value])\n",
    "    return table\n",
    "\n",
    "# Get file path input from the user\n",
    "file_path = input(\"Enter the path to your code file:\\n\")\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    code = file.read()\n",
    "\n",
    "# Determine the language based on the file extension\n",
    "if file_path.endswith(\".java\"):\n",
    "    lexer = JavaLexer(code)\n",
    "    tokens = lexer.tokenize()\n",
    "elif file_path.endswith(\".c\"):\n",
    "    lexer = CLexer(code)\n",
    "    tokens = lexer.tokenize()\n",
    "elif file_path.endswith(\".cpp\"):  # Add C++ lexer handling\n",
    "    lexer = CppLexer(code)\n",
    "    tokens = lexer.tokenize()\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "token_table = generate_token_table(tokens)\n",
    "\n",
    "# Print token table\n",
    "print(tabulate(token_table, headers=[\"Token Type\", \"Value\"], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a536b-f3e8-4b0c-ad43-87c3c31f7da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
